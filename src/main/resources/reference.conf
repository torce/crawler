akka {
  actor {
    provider = "akka.cluster.ClusterActorRefProvider"
    deployment {
      /manager/crawler {
        router = round-robin
        resizer {
          lower-bound = 2
          upper-bound = 10
        }
      }
    }
  }
  remote {
    netty.tcp {
      hostname = "127.0.0.1"
      port = 0
    }
  }

  cluster {
    seed-nodes = [
      "akka.tcp://ClusterSystem@127.0.0.1:2551"
      ]
    auto-down = on
  }

  loglevel = INFO
}

spray.can {
  host-connector {
    max-redirects = 5
    max-connections = 10
  }
  client {
    receive-timeout = 60
    user-agent-header = "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/34.0.1847.132 Safari/537.36"
  }
}

scrawl {
  master {
    class = "es.udc.scrawl.master.MasterCouch"
    retry-timeout = 15000
    couch {
      create-db = true
      hostname = "localhost"
      port = 5984
      db-name = "tosks"
      query-timeout = 60000
    }
  }
  manager {
    class = "es.udc.scrawl.Manager"
    batch-size = 25
    retry-timeout = 1000
  }
  crawler {
    class = "es.udc.scrawl.crawler.LinkExtractor"
  }
  downloader {
    class = "es.udc.scrawl.Downloader"
  }
  request-pipeline {
    retry-timeout = 100
    stages = ["es.udc.scrawl.pipeline.RobotsFilter",
              "es.udc.scrawl.pipeline.AjaxLinksTransform",
              "es.udc.scrawl.pipeline.FilterHttpError",
              "es.udc.scrawl.pipeline.RetryHttpError"]
  }
  result-pipeline {
    retry-timeout = 100
    stages = ["es.udc.scrawl.pipeline.MaxDepthFilter"]
  }
  max-depth-filter {
    max-depth = 2
  }
  filter-http-error {
    errors = [403, 500]
  }
  retry-http-error {
    errors = [404]
    max-retries = 1
  }
  custom-user-agent {
    user-agent = "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/34.0.1847.132 Safari/537.36"
  }
  robots-filter {
    retry-timeout = 5000
  }
}
